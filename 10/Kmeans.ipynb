{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2643c53d",
   "metadata": {
    "id": "2643c53d"
   },
   "source": [
    "# Klasterovanje\n",
    "\n",
    "Sadr≈æaj sveske: \n",
    "\n",
    "1. ≈†ta je klasterovanje\n",
    "2. K-means\n",
    "3. Bisecting K-means\n",
    "4. Fuzzy C-means\n",
    "\n",
    "\n",
    "**Klasterovanje** se mo≈æe definisati kao problem identifikacije grupa u podacima na naƒçin da su elementi u jednoj grupi(klasteru) jako sliƒçni, dok su elementi iz razliƒçitih klastera veoma razliƒçiti. Sliƒçnost/razliƒçitost su predstavljeni nekom merom sliƒçnosti/razliƒçitosti (npr. euklidsko rastojanje, varijansa...). Odluka koja mera sliƒçnosti ƒáe biti kori≈°ƒáena zavisi od upotrebe.\n",
    "\n",
    "Klasterovanje spada u metodu _nenadgledanog uƒçenja_, sa obzirom na to da nemamo informacije o klasterima u kojima se nalaze instance na osnovu kojih bismo evaluirali performanse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d5a92",
   "metadata": {
    "id": "569d5a92"
   },
   "source": [
    "Pojam klasterovanja nije jednoznaƒçno definisan. U jednom skupu se mo≈æe identifikovati vi≈°e razliƒçitih grupisanja.\n",
    "![](Downloads/OIP.jfif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf1bbd",
   "metadata": {
    "id": "5cdf1bbd"
   },
   "source": [
    "Pojam klasterovanja nije jednoznaƒçno definisan ne samo u odnosu na broj\n",
    "klastera koji se u podacima mogu naƒái, veƒá i u odnosu na to kako defini≈°emo klastere.\n",
    "Neke od vrsta su:  (Napomena: Ovde navodimo samo vrste koje ƒáe biti pokrivene na va≈æbama)\n",
    "\n",
    "* globularni\n",
    "* gustinski\n",
    "* dobro razdvojeni\n",
    "* hijerarhijski\n",
    "* fuzzy\n",
    "* .....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e1de6",
   "metadata": {
    "id": "195e1de6"
   },
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c39abf7",
   "metadata": {
    "id": "2c39abf7"
   },
   "source": [
    "Metoda zasnovana na reprezentativnim predstavnicima. Vr≈°i podelu podataka na disjunktne klastere.\n",
    "Najpopularnije tehnike:\n",
    "\n",
    "* K-means\n",
    "* K-medoid \n",
    "\n",
    "K-means defini≈°e predstavnika kao centroidu (najƒçeƒáe usrednjena vrednost elemenata klastera), dok K-medoid defini≈°e predstavnika kao medoidu (mora da bude taƒçka iz podataka!)\n",
    "\n",
    "U nastavku ƒáemo se baviti K-means algoritmom, dok istra≈æivanje o K-medoid ostaje za domaƒçi [literatura](https://scikit-learn-extra.readthedocs.io/en/stable/generated/sklearn_extra.cluster.KMedoids.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d579349f",
   "metadata": {
    "id": "d579349f"
   },
   "source": [
    "K-means je jedna od najstarijih i naj≈°ire kori≈°ƒáenih algoritama za klasterovanje.\n",
    "\n",
    "K-means predstavlja **iterativni** algoritam koji deli podatke u _K_ klastera (**broj klastera unapred definisan**).\n",
    "Svaka taƒçka pripada **taƒçno jednom klasteru**.\n",
    "\n",
    "Dodeljuje instance klasterima na naƒçin da suma kvadrata rastojanja izmeƒëu taƒçaka iz klastera i centroide bude ≈°to manja.\n",
    " Ova pretpostavka ƒçini algoritam primenljivim samo na\n",
    "podatke koji se mogu uproseƒçavati, poput vektora. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f87e88",
   "metadata": {
    "id": "32f87e88"
   },
   "source": [
    "Polaznih _k_ centroida se bira nasumiƒçno (mada, ako znamo ne≈°to o\n",
    "strukturi podataka, mo≈æemo ih i unapred zadati), a potom se ponavljaju\n",
    "sledeƒái koraci:\n",
    "\n",
    "1. rasporediti sve instance u nove klastere tako ≈°to se svaka instanca pridru≈æi najbli≈æoj centoridi\n",
    "2. izraƒçunati nove centroide kao prosek instanci koje su im pridru≈æene.\n",
    "\n",
    "Ovi koraci se izvr≈°avaju sve dok se centroide menjaju. Kada su centroide iste\n",
    "u dve uzastopne iteracije, algoritam se zaustavlja.\n",
    "\n",
    "U okviru ovog algoritma se vr≈°i minimizacija:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5441f",
   "metadata": {
    "id": "0cf5441f"
   },
   "source": [
    "$\n",
    "SSE = \\sum_{i=1}^{k}\\sum_{x\\in C_i} d(x, c_i)^2\n",
    "$\n",
    "po $ c_i $, gde je **_d_** euklidsko rastojanje (ali je moguƒáe koristiti i neko drugo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab297e3",
   "metadata": {
    "id": "eab297e3"
   },
   "source": [
    "### Pozitivne strane\n",
    "\n",
    " * üëç Jednostavan, fleksibilan, efikasan. \n",
    " * üëç Jednostavan za interpretaciju.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe32b3",
   "metadata": {
    "id": "ebbe32b3"
   },
   "source": [
    "### Potencijalni problemi\n",
    " * ü§î -> üëç _Da li postoji vi≈°e jednako dobrih klastera (da li postoji vi≈°e globalnih minimuma?)_ - Da, mo≈æe biti vi≈°e jednako dobrih podela (vi≈°e globalnih minimuma).\n",
    " * ü§î -> üí° -> üëç   _Da li se prilikom minimizacije mo≈æemo zaglaviti u lokalnom minimumu?_ - Da, ≈°to mo≈æe biti problem, ali ga re≈°avamo pokretanjem algoritma vi≈°e puta.\n",
    " * ü§î Pronalazi globularne klastere - ako minimizujemo eulidsko rastojanje. (mo≈æe da bude problem, zavisi od problema koji re≈°avamo).\n",
    " * üëé Osetljiv na autjalere - zbog kvadriranja euklidskog rastojanja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0b2be",
   "metadata": {
    "id": "8cc0b2be"
   },
   "source": [
    "### Primer 1 - Klasterovanje pasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4d161",
   "metadata": {
    "id": "3af4d161"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec309a3",
   "metadata": {
    "id": "dec309a3"
   },
   "source": [
    "U uvodnom primeru ƒáemo koristiti skup podataka _dogs_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17afeea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "e17afeea",
    "outputId": "fb213c4b-ddc2-41af-ded3-0a0dab08f352"
   },
   "outputs": [],
   "source": [
    "dogs = pd.read_csv('datasets/dogs.csv')\n",
    "dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984909a",
   "metadata": {
    "id": "0984909a"
   },
   "source": [
    "Po≈°to postoje dva numeriƒçka atributa, mo≈æemo ih i vizuelizovati. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c66ccf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "79c66ccf",
    "outputId": "e91a3a5f-372f-4120-9b6d-96ad8e767359"
   },
   "outputs": [],
   "source": [
    "plt.scatter(dogs['height'], dogs['weight'])\n",
    "plt.xlabel('height')\n",
    "plt.ylabel('weight')\n",
    "plt.title(\"Dogs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7e3ed",
   "metadata": {
    "id": "7fa7e3ed"
   },
   "source": [
    "Klasterovanje ƒáemo izvr≈°iti na osnovu atributa _height_ i _weight_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69864fb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69864fb8",
    "outputId": "18595fb2-85f6-4633-f752-199b82f9a65e"
   },
   "outputs": [],
   "source": [
    "feature_names = dogs.columns[1:]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a15c72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "c7a15c72",
    "outputId": "0b847df1-f213-4f98-94f3-4ef8b85da965"
   },
   "outputs": [],
   "source": [
    "X = dogs[feature_names]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4aac52",
   "metadata": {
    "id": "db4aac52"
   },
   "source": [
    "‚ùî Da li je potrebno izvr≈°iti normalizaciju prilikom kori≈°ƒáenja K-means? (Da, za≈°to?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21240f4",
   "metadata": {
    "id": "d21240f4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe39a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "41fe39a7",
    "outputId": "f676ba82-9811-4626-8441-c54ca1e1d9a0"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=feature_names)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257e2de",
   "metadata": {
    "id": "5257e2de"
   },
   "source": [
    "Nakon normalizacije vr≈°imo klasterovanje u 2 klastera, koristeƒái algoritam K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d341e0a",
   "metadata": {
    "id": "7d341e0a"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "kmeans = KMeans(n_clusters=2, n_init='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6794aef5",
   "metadata": {
    "id": "6794aef5"
   },
   "source": [
    "‚ùî Za≈°to ne vr≈°imo podelu podataka na trening i test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13060b99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "13060b99",
    "outputId": "44371a5c-7489-44d3-dd28-bf6d721484c3"
   },
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774dcd74",
   "metadata": {
    "id": "774dcd74"
   },
   "source": [
    "Sada ƒáemo da vizuelizujemo rezultate koje smo dobili. Neke bitne informacije su nam:\n",
    "   \n",
    "   * Koja instanca pripada kom klasteru\n",
    "   * Vrednosti centroida za svaki od klastera\n",
    "   * Kolika je SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d608636",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "8d608636",
    "outputId": "18a44e82-a640-4acf-976e-0b8a3fafe9e6"
   },
   "outputs": [],
   "source": [
    "# koja instanca pripada kom klasteru\n",
    "X[kmeans.labels_ == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60b2b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "fb60b2b5",
    "outputId": "64e02d84-970f-41b0-afa2-4e604f6bbd80"
   },
   "outputs": [],
   "source": [
    "\n",
    "# centroide\n",
    "centers = pd.DataFrame(kmeans.cluster_centers_, columns=feature_names)\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1072f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ec1072f",
    "outputId": "a45e87e5-83b8-4422-dcc5-8ac0ec2eaddb"
   },
   "outputs": [],
   "source": [
    "# SSE\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9fd99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "fed9fd99",
    "outputId": "a242e2f6-0c11-464c-844e-fc262b0fdf74"
   },
   "outputs": [],
   "source": [
    "plt.scatter(centers['height'], centers['weight'], marker='X', label='centroids')\n",
    "\n",
    "for c in np.unique(kmeans.labels_):\n",
    "    elems = X[kmeans.labels_ == c]\n",
    "    plt.scatter(elems['height'], elems['weight'], label=c)\n",
    "\n",
    "plt.xlabel('height')\n",
    "plt.ylabel('weight')\n",
    "plt.title('Two clusters with sse {}'.format(round(kmeans.inertia_, 2)))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dada61",
   "metadata": {
    "id": "b5dada61"
   },
   "source": [
    "Detaljnijim pregledom klastera, vidimo da su u jednom klasteru velike rase, a u drugom srednje i male rase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813ceee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "5813ceee",
    "outputId": "a10c26c1-d970-4f82-98ce-578df62e4261"
   },
   "outputs": [],
   "source": [
    "dogs[kmeans.labels_ == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700ec74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "e700ec74",
    "outputId": "e6145719-2e7b-44e6-a6be-7214b53fad1b"
   },
   "outputs": [],
   "source": [
    "dogs[kmeans.labels_ == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18kfhZRGV8JR",
   "metadata": {
    "id": "18kfhZRGV8JR"
   },
   "source": [
    "#### Silhouette coefficient (koeficijent senke)\n",
    "\n",
    "**Cohesion** - meri koliko su bliski(sliƒçni) objekti iz istog kluatera (npr. SSE)\n",
    "\n",
    "**Separation** - meri koliko su razliƒçitit objekti iz razliƒçitih klastera (npr. SE)\n",
    "\n",
    "**Silhouette coefficient** je popularan metod evaluacije klastera koja kombinuje koheziju i separaciju.\n",
    "\n",
    "Koeficijent senke se raƒçuna za svaku instancu pojedinaƒçno, na sledeƒái naƒçin:\n",
    "\n",
    "1. Za $i$-tu instancu raƒçunamo usrednjeno rastojanje od svih instanci iz istog klastera (Umesto rastojanja mo≈æe da se koriste i druge mere razliƒçitosti). Obele≈æimo izraƒçunatu vrednost sa $a_i$.\n",
    "\n",
    "2. Za $i$-tu instancu i sve klastere koji ne sadr≈æe $i$-tu instancu raƒçunamo usrednjeno rastojanje instance od svih elemenata iz svakog klastera. Pronalazimo minimalno rastojanje i obele≈æimo ga sa $b_i$.\n",
    "\n",
    "3. silhouette coefficient za $i$-tu instancu raƒçunamo : $s_i = \\frac{b_i - a_i}{max(a_i, b_i)}$\n",
    "\n",
    "Vrednosti $s_i$ se nalazi u rasponu od -1 do 1. Negativne vrednosti nisu po≈æeljne, po≈°to odgovaraju sluƒçaju kada je $a_i > b_i$, tj. da je usrednjeno rastojanje izmeƒëu instanci u klasteru veƒáe nego minimalno usrednjeno rastojanje \n",
    "od instanci iz drugih klastera.\n",
    "\n",
    "Te≈æimo da koeficijent senke bude pozitivan ($a_i < b_i$) i da $a_i$ bude ≈°to bli≈æi 0.\n",
    "\n",
    "Silhouette coefficient klastera raƒçunamo kao srednju vrednost $s_i$ instanci iz klastera.\n",
    "\n",
    "\n",
    "Kao ukupna mera kvaliteta klasterovanja se dobija usrednjavanjem $s_i$ svih instanci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RdxjeYFuhk0l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdxjeYFuhk0l",
    "outputId": "44cc2060-05a4-4059-faee-00642dbfa1a8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "silhouette_values = silhouette_samples(X, kmeans.labels_)\n",
    "silhouette_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YV4DbLZajMGw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "YV4DbLZajMGw",
    "outputId": "2a7fa59e-b417-4845-b691-7973aee4777b"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X['height'], X['weight'], c = silhouette_values, cmap=\"Greens\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Silhouette coefficient za svaku instancu za Kmeans k = 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb68ec",
   "metadata": {
    "id": "5adb68ec"
   },
   "source": [
    "### Izbor broja klastera\n",
    "\n",
    "Jedan od glavnih izazova pri kori≈°ƒáenju Kmeans je izbor broja klastera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8abd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "35b8abd1",
    "outputId": "be5c7fd6-2c3a-4a3b-c35c-0a9ffe07c3e9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "ks = range(2, X.shape[0]) # [)\n",
    "inits = ['random', 'k-means++']\n",
    "fig = plt.figure(figsize=(10,30))\n",
    "idx = 1\n",
    "silhouette = []\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    for init in inits:\n",
    "        kmeans = KMeans(n_clusters=k, init=init, n_init='auto')\n",
    "        kmeans.fit(X)\n",
    "        if init == 'k-means++':\n",
    "            inertias.append(kmeans.inertia_)\n",
    "            silhouette.append(silhouette_score(X, kmeans.labels_))\n",
    "\n",
    "        fig.add_subplot(len(ks), len(inits), idx)\n",
    "        idx += 1\n",
    "        for label in range(k):\n",
    "            cluster = dogs[kmeans.labels_ == label]\n",
    "            plt.scatter(cluster['height'], cluster['weight'])\n",
    "        \n",
    "        centroids = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=feature_names)\n",
    "        plt.scatter(centroids['height'], centroids['weight'], color='black', marker='x')\n",
    "            \n",
    "        plt.title(f'k={k}, init={init}, inertia={kmeans.inertia_}')\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ce2ad",
   "metadata": {
    "id": "8d5ce2ad"
   },
   "source": [
    "Cilj je da minimizujemo SSE(inertia). \n",
    "Sa porastom broja klastera, SSE se smanjuje, jer ƒáe instance biti bli≈æe centroidama. SSE je najmanja kada je broj klastera jednak broju instnci (svaki klaster sadr≈æi po 1 instancu). \n",
    "Sa obzirom na ovu informaciju, potrebno je da odredimo minimalan broj klastera takav da je razumna vrednost SSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NKSui0CbBWPQ",
   "metadata": {
    "id": "NKSui0CbBWPQ"
   },
   "source": [
    "#### Pravilo lakta (Elbow method) vs Silhouette coefficient\n",
    "\n",
    "Jedan od najpoznatijih metoda je **pravilo lakta**. Prvo vizuelizujemo promenu SSE. Biramo broj klastera $k$ na \"laktu\", tj. u taƒçki gde SSE najbr≈æe opadne. Na osnovu grafika ispod, izabrali bismo k=3.\n",
    "\n",
    "Problem koji se javlja prilikom kori≈°ƒáenja ove heuristike je ≈°to se klasteri koji su jako blizu spajaju u jedan (jer njihovim razdvajanjem SSE neƒáe mnogo opasti).\n",
    "\n",
    "Za re≈°enje ovog problema se koristi Silhouette coefs. Na slici desno je vizuelizovana promena silhouette coefs u odnosu na promenu broja klastera. Znamo da te≈æimo ≈°to veƒáim vrednostima, koje signaliziraju da je dobra koherencija unutar klastera, kao i separacija izmeƒëu klastera. \n",
    "\n",
    "Ako smo mo≈æda kod metoda lakta mogli da diskutujemo da li je bolje izabrati vrednost k=3 ili k=4, kori≈°ƒáenjem silhouette coefs je oƒçigledno da je optimalno k=3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac2d43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "61ac2d43",
    "outputId": "d46f4a30-e15b-4bbd-80b1-e218410d2542"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(ks, inertias, marker='o')\n",
    "plt.ylabel('inertia')\n",
    "plt.xlabel('num_of_clusters')\n",
    "plt.title('Elbow method')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ks, silhouette, marker=\"o\")\n",
    "plt.ylabel('silhouette coefs')\n",
    "plt.xlabel('num_of_clusters')\n",
    "plt.title('Silhouette coefs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OC1JC9PtID2E",
   "metadata": {
    "id": "OC1JC9PtID2E"
   },
   "source": [
    "##### Silhouette Diagram\n",
    "Jo≈° detaljnija vizuelizacija je silhouette dijagram koji se dobija vizuelizacijom silhouette coef za svaku instancu klastera, sortirane opadajuƒáe.\n",
    "Debljina svakog klastera nam daje informaciju o veliƒçini klastera, a ≈°irina o silhouette skoru svake instance (≈°to je ≈°ira to je bolje).\n",
    "\n",
    "Dodatna informacija je i isprekidana linija koja predstavlja shilouette score svih klastera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mo6e8hMuIW41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mo6e8hMuIW41",
    "outputId": "b8b88bf8-3328-484c-bf3e-4ecaed575bd9"
   },
   "outputs": [],
   "source": [
    "# pomoƒána funkcija za silhouette diagram plot (preuzeto sa https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "for n_clusters in [2, 3, 4, 5]:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, n_init=\"auto\", random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.3, -0.2, -0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(\n",
    "        X['height'], X['weight'], marker=\"o\", lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(\n",
    "        centers[:, 0],\n",
    "        centers[:, 1],\n",
    "        marker=\"o\",\n",
    "        c=\"white\",\n",
    "        alpha=1,\n",
    "        s=200,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % n_clusters,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CZY9cOj3NPgJ",
   "metadata": {
    "id": "CZY9cOj3NPgJ"
   },
   "source": [
    "Sa leve strane se nalazi silhouette diagram, a sa desne su prikazani klasteri.\n",
    "Ako posmatramo za k=2, mo≈æemo primetiti da je klaster 1 znatno veƒái od klastera 0.\n",
    "Ako poveƒáamo na k=3, dobijamo bolje rezultate. Ako sada posmatramo k=4, mo≈æemo primetiti da je silhouette score opao, kao i da se u klasteru 0 veƒáina instanci nalazi sa leve strane isprekidane linije (silhouette score je manji od sr. vrednosti), ƒçak i da je za neke instance manji od 0 (≈°to znaƒçi da je do≈°lo do pogre≈°nog razdvajanja klastera). Ovim smo jo≈° sigurniji da je k=3 najbolji izbor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa8e64",
   "metadata": {
    "id": "8efa8e64"
   },
   "source": [
    "## Primer 2 - kompresija slike \n",
    "\n",
    "Jo≈° jedan primer upotrebe klasterovanja.\n",
    "Ako ≈æelimo da kompresujemo sliku mo≈æemo smanjiti broj boja koje koristimo za prikaz.\n",
    "\n",
    "Slika u boji predstavlja matricu piksela, koji je opisan sa 3 kanala (rgb).  Svaki piksel posmatramo kao 1 instancu i izvr≈°imo klasterovanje u _k_ grupa. \n",
    "\n",
    "Nakon toga, svaki piksel zamenjujemo centroidom klastera kome pripada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3125178",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "id": "b3125178",
    "outputId": "94698f9c-c5c0-43ca-dd60-113b596c4455"
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "img = imread('img/masa.jpg')\n",
    "img_size = img.shape\n",
    "\n",
    "\n",
    "X_img = img.reshape(img_size[0] * img_size[1], img_size[2])\n",
    "\n",
    "\n",
    "km = KMeans(n_init='auto', n_clusters=30)\n",
    "km.fit(X_img)\n",
    "\n",
    "\n",
    "X_compressed = km.cluster_centers_[km.labels_]\n",
    "X_compressed = np.clip(X_compressed.astype('uint8'), 0, 255)\n",
    "\n",
    "X_compressed = X_compressed.reshape(img_size[0], img_size[1], img_size[2])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[1].imshow(X_compressed)\n",
    "ax[1].set_title('Compressed Image with 30 colors')\n",
    "for ax in fig.axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a594e1",
   "metadata": {
    "id": "23a594e1"
   },
   "source": [
    "## Bisecting K-means\n",
    "\n",
    "Bisecting K-means algorithm se zasniva na ideji: Prvo podeliti instance u 2 klastera, zatim izabrati jedan od postojeƒáih i podeliti ga na 2 klastera. Proces se ponavlja dok se ne formira $k$ klastera.\n",
    "\n",
    "Izbor klastera za podelu se mo≈æe izvr≈°iti na vi≈°e naƒçina: mo≈æemo izabrati najveƒái klaster, klaster sa najveƒáom SSE ili kriterijum koji se zasniva na SSE i veliƒçini. Ova odluka utiƒçe na rezultujuƒáe klastere.\n",
    "\n",
    "ƒåesto se rezultujuƒáe centroide Bisecting K-means algoritma koriste kao inicijalne centroide za klasiƒçan K-means pronalazi algoritam. Ovaj korak je potreban po≈°to K-means pronalazi klastere koji predstavljaju lokalni minimum u odnosu na SSE, dok kod Bisecting K-means Kmeans koristimo samo lokalno, za podelu izabranog klastera. Dakle, finalni skup klastera nije klasterovanje koje predstavlja lokalni minimum u odnosu na SSE (na poƒçetku sveske smo definisali klasterovanje kao minimizacioni problem SSE).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0132c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "ebf0132c",
    "outputId": "fc0bf5d1-3d5f-4710-d369-93677f000577"
   },
   "outputs": [],
   "source": [
    "from sklearn. cluster import BisectingKMeans\n",
    "bkmeans = BisectingKMeans(n_clusters=3,bisecting_strategy='largest_cluster')\n",
    "bkmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ff047",
   "metadata": {},
   "source": [
    "###### Pomoƒána funkcija za vizuelizaciju klasterovanja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clustering(data, centers, labels, feature_names, alg_name):\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], marker='X', label='centroids', color=\"black\")\n",
    "\n",
    "    for c in np.unique(labels):\n",
    "        elems = X[labels == c]\n",
    "        plt.scatter(elems[feature_names[0]], elems[feature_names[1]], label=c)\n",
    "\n",
    "    plt.xlabel(feature_names[0])\n",
    "    plt.ylabel(feature_names[0])\n",
    "    plt.title('{} {} clusters'.format(alg_name, len(centers)))\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed93a7",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "98ed93a7",
    "outputId": "2e4105b3-c573-4249-c6cd-75bc6f2b906f"
   },
   "outputs": [],
   "source": [
    "bkmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873cd014",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "873cd014",
    "outputId": "d07f1f85-dae5-4429-d2ee-91bf4e0543f5"
   },
   "outputs": [],
   "source": [
    "visualize_clustering(X, bkmeans.cluster_centers_, bkmeans.labels_, X.columns, \"Bisecting Kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654492a",
   "metadata": {
    "id": "1654492a"
   },
   "source": [
    "## Fuzzy C - Means\n",
    "\n",
    "Svi algoritmi sa kojima smo se do sada upoznali su **hard clustering**, tj. jedna taƒçka pripada najvi≈°e jednom klasteru. \n",
    "Nasuprot tome, postoje i **soft clustering** algoritmi koji dozvoljavaju da taƒçke pripadaju istovremeno veƒáem broju klastera sa razliƒçitim stepenom pripadnosti (membership degree/value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1db58",
   "metadata": {},
   "source": [
    "Fuzzy C-means (FCM) je jedan predstavnik soft clustering algoritama. C-means u nazivu oznaƒçava $c$ centroida (identiƒçno kao kod K-means).\n",
    "\n",
    "Kod Fuzzy C-means metoda, imamo **dva parametra** : $\\mu_{ij}$ i $c_i$ i **hiper-parametare** : c i m.\n",
    "\n",
    "* $\\mu_{ij}$ - membership degree/value (stepen pripadnosti) - verovatnoƒáa da $j$-te instanca pripada $i$-tom klasteru.\n",
    "Ograniƒçenja:\n",
    "    \n",
    "    * $\\mu_{ij} \\in [0, 1]$   $\\forall i, j$\n",
    "     \n",
    "    \n",
    "    * $\\sum_{i=1}^{c} \\mu_{ij} = 1$  $\\forall j$\n",
    " \n",
    "\n",
    "* $c_i$ - centroide za svaki klaster\n",
    "\n",
    "* $m >= 1$ - fuzzifier - kontroli≈°e koliko ƒáe granice klastera biti fuzzy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a67ebb",
   "metadata": {},
   "source": [
    "### Minimizacioni problem\n",
    "\n",
    "You can understand the objective function as a weighted sum of the distance between the data points (X_j) and the cluster centers (C_i). The ‚Äúdistance‚Äù term is the L2 norm in the equation above, and in the example\n",
    "\n",
    "$ J = \\sum_{i=1}^{C}\\sum_{j=1}^{N}\\mu_{ij}^md(x_j, c_i)$, gde je\n",
    "\n",
    "$C$ - broj klastera\n",
    "$N$ - broj instanci \n",
    "$x_j$ - $j$-ta instanca\n",
    "$c_i$ - centroida za $i$-ti klaster\n",
    "$d$ - rastojanje, npr. L2 norma (euklidsko rastojanje)\n",
    "\n",
    "Formula predstavlja _te≈æinsku sumu_ rastojanja izmeƒëu taƒçaka iz podataka ($x_j$) i centroide klastera ($c_i$).\n",
    "\n",
    "Suma je \"ote≈æana\" sa $\\mu{ij}^m$. Po≈°to minimizujemo $J$, za bli≈æe instance centroidi imamo veƒáe vrednosti $\\mu_{ij}$. Zato nam je bitan i hiper-parametar $m$.  Ako za vrednost m uzmemo jako velike vrednosti, rastojanje vi≈°e nema veliki uticaj (jer je $\\mu_{ij}^m$ blisko 0) i sve centroide ƒáe se nalaziti oko centra svih podataka - time se onda sve taƒçke nalaze u velikom broju klastera. \n",
    "\n",
    "Dakle, intuitivno, za veliko $m$ - instance pripadaju veƒáem broju klastera, za malo $m$ - instance pripadaju malom broju klastera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96637ef2",
   "metadata": {},
   "source": [
    "#### Pronalazak parametara koji minimizuju J \n",
    "\n",
    "[Litetatura sa izvoƒëenjem formula.](https://www.sciencedirect.com/science/article/abs/pii/0098300484900207)\n",
    "\n",
    "Ostalo je jo≈° pitanje pronalaska parametara $c_i$ i $\\mu_{ij}$ koji minimizuju $J$:\n",
    "\n",
    "* $c_i = \\frac{\\sum_{j=1}^N \\mu_{ij}^mxj}{\\sum_{j=1}^N \\mu_{ij}^m}$\n",
    "* $\\mu_{ij} = \\frac{1}{\\sum_{k=1}^{C}(\\frac{||x_j-c_i||}{||x_j-c_k||})^{\\frac{2}{m-1}}}$\n",
    "\n",
    "Dakle, Fuzzy C means iterativno a≈æurira $c_i$ i $\\mu_{ij}$ sve dok promene centroida u dve uzastopne iteracije nije manja od unapred odreƒëene granice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fa595",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "866fa595",
    "outputId": "de363432-773c-4aa3-b0ea-f1940ebc7849"
   },
   "outputs": [],
   "source": [
    "#pip install scikit-fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f913a",
   "metadata": {},
   "source": [
    "U narednom primeru ƒáemo prikazati kori≈°ƒáenje FCM. Nakon pode≈°avanja parametara c i m, odreƒëujemo klastere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4632d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "fc4632d1",
    "outputId": "29d50753-5b49-477e-f2c4-7ff0e06b7062"
   },
   "outputs": [],
   "source": [
    "#pip install fuzzy-c-means\n",
    "from fcmeans import FCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xjjCMOCK3RQ6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjjCMOCK3RQ6",
    "outputId": "c98c5bea-e84d-4c48-98d9-f7909ec997f4"
   },
   "outputs": [],
   "source": [
    "fcm = FCM(n_clusters=3, m=3)\n",
    "fcm.fit(X.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13288d94",
   "metadata": {},
   "source": [
    "FCM mo≈æemo koristiti i za hard clustering, kada svaku instancu dodelimo jednom klasteru (onom za koji je stepen pripadnosti najveƒái)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62615af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard clustering - dodeljivanje tacno jednom klasteru\n",
    "labels = fcm.predict(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e-iejx4h32zz",
   "metadata": {
    "id": "e-iejx4h32zz"
   },
   "outputs": [],
   "source": [
    "centers = fcm.centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14515a15",
   "metadata": {},
   "source": [
    "Na osnovu vizuelizacije ispod, vidimo da smo dobili sliƒçne centroide kao sa K-means ili Bisecting K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clustering(X, fcm.centers, fcm.predict(X.to_numpy()), X.columns, \"Fuzzy Kmeans\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c599b",
   "metadata": {},
   "source": [
    "Da bismo dobili informacije o stepenu pripadnosti razliƒçitim klasterima, koristiƒáemo soft_predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5106133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(fcm.soft_predict(X.to_numpy()), cmap='Greens', annot=True)\n",
    "plt.title(\"Membership values\")\n",
    "plt.xlabel('clusters')\n",
    "plt.ylabel('data objects')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648f794",
   "metadata": {},
   "source": [
    " Pitanje? Da li gore pokazanim heuristikama za hard clustering mo≈æemo da biramo broj klastera za fuzzy c means?\n",
    " [Dodatna literatura](https://ieeexplore.ieee.org/document/6412415)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
